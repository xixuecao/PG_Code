{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self, parent=None):\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.label = None\n",
    "        self.classCounts = None\n",
    "        self.splitFeatureValue = None\n",
    "        self.splitFeature = None\n",
    "\n",
    "def dataToDistribution(data):\n",
    "    '''Turn a dataset which has n possibe classification labels into a \n",
    "       probability distribution with n entries.'''\n",
    "    allLabels = [label for (point,label) in data]\n",
    "    numEntries = len(allLabels)\n",
    "    possibleLabels = set(allLabels)\n",
    "    \n",
    "    dist = []\n",
    "    for aLabel in possibleLabels:\n",
    "        dist.append(float(allLabels.count(aLabel)) / numEntries)\n",
    "    return dist\n",
    "\n",
    "def entropy(dist):\n",
    "    '''Compute the Shannon entropy of the given probability distribution.'''\n",
    "    return -sum([p*math.log(p,2) for p in dist])\n",
    "\n",
    "def splitData(data, featureIndex):\n",
    "    attrValues = [point[featureIndex] for (point, label) in data]\n",
    "    for aValue in set(attrValues):\n",
    "        dataSubset = [(point, label) for (point, label) in data\n",
    "                      if point[featureIndex] == aValue]\n",
    "        yield dataSubset\n",
    "\n",
    "def gain(data, featureIndex):\n",
    "    entropyGain = entropy(dataToDistribution(data))\n",
    "    for dataSubset in splitData(data,featureIndex):\n",
    "        entropyGain -= entropy(dataToDistribution(dataSubset))\n",
    "    return entropyGain\n",
    "\n",
    "def homogeneous(data):\n",
    "    return len(set([label for (point,label) in data])) <= 1\n",
    "\n",
    "def majorityVote(data,node):\n",
    "    labels = [label for (pt,label) in data]\n",
    "    choice = max(set(labels), key=labels.count)\n",
    "    node.label = choice\n",
    "    return node\n",
    "\n",
    "def buildDecisionTree(data, root, remainingFeatures):\n",
    "    if homogeneous(data):\n",
    "        root.label = data[0][1]\n",
    "        return root\n",
    "    if len(remainingFeatures) == 0:\n",
    "        return majorityVote(data, root)\n",
    "    bestFeature = max(remainingFeatures, key=lambda index: gain(data, index))\n",
    "    if gain(data, bestFeature) == 0:\n",
    "        return majorityVote(data,root)\n",
    "    root.splitFeature = bestFeature\n",
    "    print(str(root.splitFeature)+' ', end='')\n",
    "    \n",
    "    for dataSubset in splitData(data, bestFeature):\n",
    "        aChild = Tree(parent=root)\n",
    "        aChild.splitFeatureValue = dataSubset[0][0][bestFeature]\n",
    "        root.children.append(aChild)\n",
    "        buildDecisionTree(dataSubset, aChild, remainingFeatures - set([bestFeature]))\n",
    "    return root\n",
    "\n",
    "def decisionTree(data):\n",
    "    return buildDecisionTree(data,Tree(),set(range(len(data[0][0]))))\n",
    "\n",
    "def classify(tree,point):\n",
    "    if tree.children == []:\n",
    "        return tree.label\n",
    "    else:\n",
    "        matchingChildren = [child for child in tree.children\n",
    "                           if child.splitFeatureValue == point[tree.splitFeature]]\n",
    "        return classify(matchingChildren[0],point)\n",
    "\n",
    "def testClassification(data, tree):\n",
    "    actualLabels = [label for point, label in data]\n",
    "    predictedLabels = [classify(tree, point) for point, label in data]\n",
    "    correctLabels = [(1 if a == b else 0) for a,b in zip(actualLabels, predictedLabels)]\n",
    "    return float(sum(correctLabels)) / len(actualLabels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 13 14 1 9 4 12 4 11 0 2 8 7 6 5 12 9 15 10 15 11 7 4 8 6 12 5 0 10 1 9 14 2 \n",
      "\t\t\t y R None\n",
      "\t\t y 14\n",
      "\t\t\t\t\t\t y R None\n",
      "\t\t\t\t\t y 4\n",
      "\t\t\t\t\t\t n R None\n",
      "\t\t\t\t y 9\n",
      "\t\t\t\t\t\t y R None\n",
      "\t\t\t\t\t n 12\n",
      "\t\t\t\t\t\t n D None\n",
      "\t\t\t n 1\n",
      "\t\t\t\t\t\t\t y R None\n",
      "\t\t\t\t\t\t y 0\n",
      "\t\t\t\t\t\t\t\t y R None\n",
      "\t\t\t\t\t\t\t n 2\n",
      "\t\t\t\t\t\t\t\t\t y R None\n",
      "\t\t\t\t\t\t\t\t n 8\n",
      "\t\t\t\t\t\t\t\t\t\t y R None\n",
      "\t\t\t\t\t\t\t\t\t n 7\n",
      "\t\t\t\t\t\t\t\t\t\t\t y R None\n",
      "\t\t\t\t\t\t\t\t\t\t n 6\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t y R None\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t y 9\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t y R None\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t n 15\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t y D None\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t n 10\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t n R None\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t y 12\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t n R None\n",
      "\t\t\t\t\t\t\t\t\t\t\t n 5\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t n R None\n",
      "\t\t\t\t\t y 11\n",
      "\t\t\t\t\t\t n R None\n",
      "\t\t\t\t n 4\n",
      "\t\t\t\t\t n R None\n",
      "\t y 13\n",
      "\t\t n R None\n",
      " 3\n",
      "\t\t\t y D None\n",
      "\t\t y 11\n",
      "\t\t\t\t\t y D None\n",
      "\t\t\t\t y 4\n",
      "\t\t\t\t\t\t\t\t y D None\n",
      "\t\t\t\t\t\t\t y 12\n",
      "\t\t\t\t\t\t\t\t\t y D None\n",
      "\t\t\t\t\t\t\t\t n 5\n",
      "\t\t\t\t\t\t\t\t\t\t\t y D None\n",
      "\t\t\t\t\t\t\t\t\t\t y 10\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t y D None\n",
      "\t\t\t\t\t\t\t\t\t\t\t n 1\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t y D None\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t y 14\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t y D None\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t n 2\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t n R None\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t n 9\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t n D None\n",
      "\t\t\t\t\t\t\t\t\t n 0\n",
      "\t\t\t\t\t\t\t\t\t\t n D None\n",
      "\t\t\t\t\t\t y 6\n",
      "\t\t\t\t\t\t\t n D None\n",
      "\t\t\t\t\t n 8\n",
      "\t\t\t\t\t\t n D None\n",
      "\t\t\t n 7\n",
      "\t\t\t\t n D None\n",
      "\t n 15\n",
      "\t\t n D None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9870689655172413"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def BinaryDecisionTree(root, indent=''):\n",
    "    if root.children == []:\n",
    "        print(indent, root.splitFeatureValue, root.label, root.classCounts)\n",
    "    else:\n",
    "        BinaryDecisionTree(root.children[0], indent + '\\t')\n",
    "\n",
    "        if indent == '': # processing the root\n",
    "            print(indent, root.splitFeature)\n",
    "        else:\n",
    "            print(indent, root.splitFeatureValue, root.splitFeature)\n",
    "        if len(root.children) == 2:\n",
    "            BinaryDecisionTree(root.children[1], indent + '\\t')\n",
    "\n",
    "import math\n",
    "with open('house-votes-1984.txt', 'r') as inputFile:\n",
    "    lines = inputFile.readlines()\n",
    "data = [line.strip().split(',') for line in lines]\n",
    "data = [(x[1:], x[0]) for x in data]\n",
    "cdata = [x for x in data if '?' not in x[0]]\n",
    "ndata = [x for x in data if '?' in x[0]] #直接去掉带？的数据\n",
    "\n",
    "tree = decisionTree(cdata)\n",
    "print()\n",
    "BinaryDecisionTree(tree)\n",
    "testClassification(cdata,tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the bestFeatue'column  is : 4\n"
     ]
    }
   ],
   "source": [
    "a = [3,13,14,1,9,4,12,4,11,0,2,8,7,6,5,12,9,15,10,15,11,7,4,8,6,12,5,0,10,1,9,14,2]\n",
    "print(\"the bestFeatue'column  is : \"+str(max(set(a), key=a.count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "剪枝叶和画出准确率与subset大小的关系图没有写\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1.\n",
    "In an image, the appearance and shape of the local target can be well described by the gradient or the density of the edge.\n",
    "\n",
    "Sampling positive images\n",
    "Sampling negative images\n",
    "Training a Linear SVM\n",
    "Performing hard-negative mining\n",
    "Re-training your Linear SVM using the hard-negative samples\n",
    "Evaluating your classifier on your test dataset, utilizing non-maximum suppression to ignore redundant, overlapping bounding boxes\n",
    "\n",
    "2.\n",
    "(1) sliding window algorithm\n",
    "Sliding window is a sub-list that runs over an underlying collection. I.e., if you have an array like\n",
    "[a b c d e f g h]\n",
    "a sliding window of size 3 would run over it like\n",
    "\n",
    "[a b c]\n",
    "  [b c d]\n",
    "    [c d e]\n",
    "      [d e f]\n",
    "        [e f g]\n",
    "          [f g h]\n",
    "\n",
    "(2) non-Maxima Suppression\n",
    "I.e.\n",
    "Discards all those cells where probability of object being present is <= 0.6\n",
    "Then it takes the cell with largest probability among candidates for object as a prediction\n",
    "Finally we discard any remaining cell with Intersection over union value >= 0.5 with the prediction cell.\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
